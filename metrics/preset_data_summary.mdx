---
title: 'Data Summary'
description: 'Overview of the Data Summary Preset.'
noindex: "true"
---

**Report.** To run a Preset on your data for a single `current` dataset:

```python
report = Report(metrics=[
    DataSummaryPreset(),
])

my_eval = report.run(current, None)
```

**Test Suite.** To add pass/fail data quality Tests, auto-generated from `ref` dataset:

```python
report = Report(metrics=[
    DataSummaryPreset(),
],
include_tests=True)

my_eval = report.run(current, ref)
```

## Overview

The`DataSummaryPreset` lets you visualize key descriptive statistics for the dataset and each column in it. If you pass two datasets, you'll get a side-by-side comparison.

![](/images/metrics/preset_dataset_summary-min.png)

* **Dataset stats.** Shows stats like number of rows/columns, empty columns/rows, etc.

* **Column stats**. Shows relevant statistics and visualizes distribution for each column. The stats are different based on the column type (numerical, categorical, text, datetime).

If you choose to enable Tests, you will get an additional Test Suite view:

![](/images/metrics/test_preset_dataset_summary-min.png)

* Tests are auto-generated:

  * **Based on reference dataset.** If the reference dataset is provided, conditions like min-max feature ranges are derived directly from it.

  * **Based on heuristics.** If there is no reference, some Tests will run with heuristics (like expect no missing values).

<Info>
  **How Tests work.** Read about [Tests](/docs/library/tests) and check defaults for each Tests in the [reference table.](/metrics/all_metrics)
</Info>

## Use case

You can use this Preset in different scenarios.

* **Exploratory data analysis.** You can use the visual Report to explore your dataset at any point (during model training, after new batch of data arrives, during debugging etc.)

* **Dataset comparison.** You can use the Report to compare two datasets to confirm similarities or understand the differences. For example, compare training and test dataset, subgroups in the same dataset, or current production data against training.

* **Data quality tests in production.** By enabling Tests, you can check the quality and stability of the input data before you generate the predictions, every time you perform a certain transformation, add a new data source, etc.

* **Data profiling in production.** You can use this preset during monitoring to capture the shape of the production data for future analysis and visualization.

## Data requirements

* **Input columns**. You can provide any input columns. They must be non-empty.

* **One or two datasets**. Pass a single dataset or two for comparison.&#x20;

* **Set column types** (Optional) The Preset evaluates numerical, categorical, text and datetime columns. You can specify column types explicitly (recommended). Otherwise Evidently will auto-detect numerical, categorical and datetime columns. You must always map text data.

* **Timestamp** (Optional). If you have a datetime index and want to learn how columm value change with time, specify the `timestamp` column in data definition. 

* **Target** (Optional). If you have a target column and want to see feature distribution by target, specify the target column in data definition.

<Info>
  **Data schema mapping**. Use the [data definition](/docs/library/data_definition) to map your input data.
</Info>

## Report customization

You have multiple customization options.

**Select columns**. You can get stats only for some columns in the Dataset. Use the `columns` parameter.

**Modify Report composition**. You can add other Metrics to the Report to get a more comprehensive evaluation. Here are some recommended options.

* **Correlations.** Add correlations heatmap.

* **Missing values** Add missing values heatmap.

* **Data drift**. Consider `DataDriftPreset` to evaluate the distribution shifts if you have two datasets.

**Customize Test conditions**. If you want to modify the auto-generated Test conditions, you can set yours: either a different condition relative to the reference or any custom conditions per each Test.  

<Info>
  **Creating a custom Report**. Check how to create a [Report](/docs/library/report) and add [Tests](/docs/library/tests) conditions.
</Info>