---
title: "Regression metrics"
description: "Open-source regression quality metrics."
noindex: "true"
---



#### **1. Model Quality Summary Metrics**

Evidently calculates a few standard model quality metrics: Mean Error (ME), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE).

<img height="704" width="2216" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-0592d3c8a92179e411b172cd8eb8884138505050%252Freg_perf_model_quality_summary.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=da983c12&sv=2" />

For each quality metric, Evidently also shows one standard deviation of its value (in brackets) to estimate the stability of the performance.

**To support the model performance analysis, Evidently also generates interactive visualizations. They help analyze where the model makes mistakes and come up with improvement ideas.**

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-2.-predicted-vs-actual)&#xA;2\. **Predicted vs Actual**

Predicted versus actual values in a scatter plot.

<img height="1078" width="2214" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-1269097ed5a2ea2a6bed82561daf473d2de81e0e%252Freg_perf_predicted_actual.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=d393d0b8&sv=2" />

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-3.-predicted-vs-actual-in-time)&#xA;3\. **Predicted vs Actual in Time**

Predicted and Actual values over time or by index, if no datetime is provided.

<img height="1070" width="2216" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252FQ6gSnWb4ytbEuGpW5YVG%252Freg_perf_predicted_actual_in_time.png%3Falt%3Dmedia%26token%3D7b3e769e-43b4-4944-b25a-5bef5426a730&width=768&dpr=4&quality=100&sign=591a244d&sv=2" />

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-4.-error-predicted-actual)&#xA;4\. Error (Predicted - Actual)

Model error values over time or by index, if no datetime is provided.

<img height="1080" width="2220" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-712477dee018c0e0c8f64bcc4cec3506a2e4bece%252Freg_perf_error.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=c90208ed&sv=2" />

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-5.-absolute-percentage-error)&#xA;5\. Absolute Percentage Error

Absolute percentage error values over time or by index, if no datetime is provided.

<img height="1074" width="2218" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-b7221d5d2c9be3177055289ee1ba043539b9e10b%252Freg_perf_abs_per_error.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=9f12e500&sv=2" />

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-6.-error-distribution)&#xA;6\. Error Distribution

Distribution of the model error values.

<img height="1084" width="2218" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-e9ac059e8fd627aa632cfad0e1a6096376205a83%252Freg_perf_error_distribution.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=b65039f0&sv=2" />

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-7.-error-normality)&#xA;7\. Error Normality

Quantile-quantile plot ([Q-Q plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot)) to estimate value normality.

<img height="1066" width="2214" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-acfd422bc65e1153cd554783d72e8b5f26086365%252Freg_perf_error_normality.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=b88a9650&sv=2" />

**After that, Evidently explores in detail two segments of the dataset: the 5% of predictions with the highest negative and positive errors. We refer to them as the "underestimation" and "overestimation" groups, respectively. The remaining predictions are referred to as the "majority" group.**

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-8.-mean-error-per-group)&#xA;**8. Mean Error per Group**

A summary of the model quality metrics for each of the two segments: mean Error (ME), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE).

<img height="678" width="2220" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-2fb0b43dbd352188ebb4ef8693a07cc53fdddd17%252Freg_perf_mean_error_per_group.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=cb821f65&sv=2" />

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-9.-predicted-vs-actual-per-group)&#xA;**9. Predicted vs Actual per Group**

Prediction plots that visualize the regions where the model underestimates and overestimates the target function.

<img height="1068" width="2218" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-6a3efa2e1605602e0056354603d6b198210029c9%252Freg_perf_predicted_actual_per_group.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=69e28b40&sv=2" />

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-10.-error-bias-mean-most-common-feature-value-per-group)&#xA;**10. Error Bias: Mean/Most Common Feature Value per Group**

This table helps quickly see the differences in feature values between the 3 groups:

* **OVER** (top-5% of predictions with overestimation)

* **UNDER** (top-5% of the predictions with underestimation)

* **MAJORITY** (the rest 90%)

For the numerical features, it shows the mean value per group. For the categorical features, it shows the most common value.

If you have two datasets, the table displays the values for both REF (reference) and CURR (current).

<img height="800" width="2190" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-cda35cf799db0f2431780cb4f03340da6e13d239%252Freg_perf_error_bias_table.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=fbd654ee&sv=2" />

If you observe a large difference between the groups, it means that the model error is sensitive to the values of a given feature.

**To search for cases like this, you can sort the table using the column "Range(%)".** It increases when either or both of the "extreme" groups are different from the majority.

Here is the formula used to calculate the Range %:

Range=100∗∣(Vover−Vunder)/(Vmax−Vmin)∣*Range*=100∗∣(*Vover*−*Vunder*)/(*Vmax*−*Vmin*)∣

***Where:** **V**over = average feature value in the OVER group; **V**under = average feature value in the UNDER group; **V**max = maximum feature value; **V**min = minimum feature value*

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-11.-error-bias-per-feature)&#xA;**11. Error Bias per Feature**

For each feature, Evidently shows a histogram to visualize the **distribution of its values in the segments with extreme errors** and in the rest of the data. You can visually explore if there is a relationship between the high error and the values of a given feature.

Here is an example where extreme errors are dependent on the "temperature" feature.

<img height="1180" width="2328" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-0f36fde30923f9a29d1c62512e42aae47a53ef54%252Freg_perf_error_bias_per_feature.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=de6937aa&sv=2" />

#### [](https://docs.evidentlyai.com/presets/reg-performance#id-12.-predicted-vs-actual-per-feature)&#xA;12\. Predicted vs Actual per Feature

For each feature, Evidently also show the Predicted vs Actual scatterplot. It helps visually detect and explore underperforming segments which might be sensitive to the values of the given feature.

<img height="1162" width="2314" src="https://docs.evidentlyai.com/~gitbook/image?url=https%3A%2F%2F256125905-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FeE67gM4508ESQxkbpOxj%252Fuploads%252Fgit-blob-12264ff6301d03477160f5b9f004d7af52476d88%252Freg_perf_error_bias_predicted_actual_per_feature.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=1992aeb7&sv=2" />

### [](https://docs.evidentlyai.com/presets/reg-performance#metrics-output)&#xA;Metrics output
