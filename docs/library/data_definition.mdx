---
title: 'Data definition'
description: 'How to map the input data.'
noindex: true
---

To run evaluations, you must create a `Dataset` object with a `DataDefinition`, which maps:

* **Column types** (e.g., categorical, numerical, text, embeddings).

* **Column roles** (e.g., prediction, target, LLM output, etc.).

This helps Evidently process the data correctly. Some evaluations require certain columns, and will fail if these are missing.

You can create a `DataDefinition` in Python before generating a Report or map the columns visually in the Evidently platform. **Automated data definition** is also available in some cases.

<Info>
Check data requirements for specific Metrics in the [Reference table](/metrics/all_metrics).
</Info>

## Basic flow

**Import** the following modules:

```python
from evidently.future.datasets import Dataset
from evidently.future.datasets import DataDefinition
```

**Create a Dataset**. You can pass data with [flexible structure](/docs/library/overview#dataset).

* Prepare it as a pandas.DataFrame. 

* Create an Evidently Dataset object using `Dataset.from_pandas`.

* Pass the corresponding `data_definition`. For automated mapping, pass an empty `DataDefinition()`object:

```python
eval_data = Dataset.from_pandas(
    pd.DataFrame(source_df),
    data_definition=DataDefinition()
)
```

**Two datasets.** If you're using two datasets (like current and reference for drift detection), create a Dataset object for each. They must have identical data definition.

**Automated data definition.**  If the data definition is not specified, Evidently tries to map columns:

* Based on type (numerical, categorical).

* By matching column names to known roles (e.g., a column "target" treated as the target).

**Manual data definition.** While automation works in many cases, manual mapping is more accurate. It helps avoid mistakes like misclassifying numerical columns with few unique values as categorical. Some evaluations, like text or embedding drift detection require explicit mapping.

<Info>
  Once you have the **Dataset** ready, you can add [text Descriptors ](/docs/library/descriptors)and/or [get Reports](/docs/library/report).
</Info>

You can explore different mapping options below. Note that you only need to use those relevant to your evals. For example, you don’t need roles like target/prediction to run data quality checks.

## Column types

**Why map them**. Mapping column types ensures accurate processing for:
* Statistical analysis. Descriptive stats adjust based on column type.
* Visualizations. This also prevents unsuitable plots (e.g., text columns treated as categorical will get an irrelevant distribution histogram).
* Data drift analysis. Drift detection methods vary by column type.
* Automated tests. Preset test choice is mapped to column types.

**Any tabular data**. Example mapping: 

```python
definition = DataDefinition(
    text_columns=["Latest_Review"],
    numerical_columns=["Age", "Salary"],
    categorical_columns=["Department"],
    datetime_columns=["Joining_Date"]
    )
    
eval_data = Dataset.from_pandas(
    pd.DataFrame(source_df),
    data_definition=definition
)
```

(TBC). **Embeddings** Example mapping:

```python
embeddings = {'small_subset': embeddings_data.columns[:10]} #TBC
```

<Info>
If you map column types manually and exlcude certain columns, they will be ignored in all evaluations even if present in the dataset.
</Info>

### Options

Available types and how automated mapping works.

| **Column Type**       | **Description** | **Automated Mapping**  |
| --------------------- | ------- | --------- |
| `numerical_columns`   | <ul><li>Columns with numeric values.</li></ul>                                                                              | All columns with numeric types (`np.number`).              |
| `datetime_columns`    | <ul><li>Columns with datetime values.</li><li>Ignored in data drift calculations.</li></ul>    | All columns with DateTime format (`np.datetime64`).        |
| `categorical_columns` | <ul><li>Columns with categorical values.</li></ul>                                                                                     | All non-numeric/non-datetime columns. |
| `text_columns`        | <ul><li>Text columns.</li><li>You can generate descriptors without explicit mapping. </li><li>Mapping required for text data drift detection.</li></ul> | No automated mapping.                    |
| `embeddings` (TBC)    | <ul><li>Columns containing embeddings.</li><li> Pass a dictionary where keys are embedding names and values are lists of columns.</li><li>Required for embedding drift detection.</li></ul>                                                                                                                                                                                                                                                                                            | No automated mapping.|



## Column roles

### General

If you have a timestamp or ID column, it's always a good idea to map them. It serves as the index for certain plots, giving you richer visualizations in your Reports. Mapping the "Timestamp" and "ID" columns also excludes them from analyses like data drift detection, where it wouldn't add any value.

| Parameter  | Description                                                                                        | Automated mapping         |
| ---------- | -------------------------------------------------------------------------------------------------- | ------------------------- |
| id\_column | id column                                                                                          | column named "id" column" |
| timestamp  | timestamp column (used as axis in some plots instead of index), only one column can be a timestamp | column named "timestamp"  |

Difference between timestamp and datetime. Datetime is a column types, timestamp is a role. It often represents the time when a data row was recorded.Use it if you want to see it as index on the plots.  There can only be one timestamp, but many dateteim columns.  A DateTime type is any time-related column in your dataset:  for example, conversation start / end, features like "date of last contact", etc.)

### LLM evals

and treat columns appropriately when computing the Metrics


llm=None,

add here on input, target\_output

descriptors auto-mapped but you can map directly too
\When you generate descriptors they are automatically tagged as descriptors.

numerical\_descriptors=\['target2', 'prediction2'], categorical\_descriptors=\[])

#### Descriptors

### Regression

, regression=None,

If you have a dataset with ML inferences, it's necessary to map where Predictions and Actuals are to compute the regression quality metrics.

show example, defaults

### Classification

classification=\[BinaryClassification()]

classification=\[BinaryClassification(name='default', target='target', prediction\_labels=None, prediction\_probas='prediction', pos\_label=1, labels=None)]

If you have a dataset with ML inferences, it's necessary to map where Predictions and Ground Truth are to compute the quality metrics.

show example, defaults

### Ranking

show example, defaults

additional dataset

***

How to define the data schema for ranking and recommendations.

To evaluate data from recommender systems, you must correctly map the input data schema. You can also pass an optional **additional dataset** with training data.

**Note**: this mapping will also apply to search and retrieval systems. Treat "user\_id" as "query\_id".

To evaluate the quality of a ranking or a recommendation system, you must pass:

* The score or rank generated by the system as the prediction.

* The relevance labels as the target (e.g., this could be an interaction result like user click, assigned relevance label, etc.)

Here are the examples of the expected data inputs.

If the model prediction is a score (expected by default):

| user\_id | item\_id | prediction (score) | target (relevance) |
| -------- | -------- | ------------------ | ------------------ |
| user\_1  | item\_1  | 1.95               | 0                  |
| user\_1  | item\_2  | 0.8                | 1                  |
| user\_1  | item\_3  | 0.05               | 0                  |

If the model prediction is a rank:

| user\_id | item\_id | prediction (rank) | target (relevance) |
| -------- | -------- | ----------------- | ------------------ |
| user\_1  | item\_1  | 1                 | 0                  |
| user\_1  | item\_2  | 2                 | 1                  |
| user\_1  | item\_3  | 3                 | 0                  |

The **target** column with the interaction result or relevance label can contain either:

* a binary label (where `1` is a positive outcome)

* any true labels or scores (any positive values, where a higher value corresponds to a better match or a more valuable user action).

You might need to add additional details about your dataset via column mapping:

* `recommendations_type`: `score` (default) or `rank`. Helps specify whether the prediction column contains ranking or predicted score.

* `user_id`: helps specify the column that contains user IDs.

* `item_id`: helps specify the column that contains ranked items.

# Additional data

Some metrics like novelty or popularity bias require training data, which has a different structure from production data. To pass it, use the `additional_data` object. You can pass your training data as `current_train_data` and (optional) `reference_train_data`.

Example:

```python
report = Report(metrics=[
   UserBiasMetric(column_name='age'),
])
report.run(reference_data=ref, current_data=cur, column_mapping=column_mapping, additional_data={'current_train_data': train})
report
```

## Requirements:

* The additional training dataset should have the following structure:

| user | item | target |
| ---- | ---- | ------ |
| id1  | id1  | 1      |
| id2  | id9  | 1      |
| id3  | id2  | 1      |
| id3  | id1  | 1      |
| id4  | id6  | 1      |

* The names of the columns with `user_id` and `item_id` should match the corresponding columns in the current (and optional reference) data.

* The name of the column with the interaction result should match the name of the `target` column in the current (and optional reference) data.

* If you use metrics that refer to specific columns (such as `UserBiasMetric` metric), these columns must also be present in the training dataset.

* You can pass a single training dataset or two datasets (in case your reference and current dataset have different training data).

### What is the difference between training and reference data?

The reference dataset can belong to a previous production period or a different model you compare against. The training dataset is used to train the model. Their structure usually differs:

* Production data typically includes a list of all recommended items, where some of them earn a positive interaction result. It also contains negative examples (ignored recommendations) and data about model prediction (predicted rank or score).

* Training data typically contains a history of positive actions, such as user viewing history, page reads, or upvotes. Since it only includes the interaction results, it lacks negative examples (e.g., ignored recommendations) and column with the model output (predicted rank or score).

***

## description: How to define the data schema for classification.

To evaluate classification model performance, you must correctly map the input data schema.

# Code example

# Column Mapping

To evaluate the classification performance, you need both true labels and prediction. Depending on the classification type (e.g., binary, multi-class, probabilistic), you have different options of how to pass the predictions.

## Multiclass classification

### Option 1

Target: encoded labels, Preds: encoded labels + Optional\[target\_names].

| target | prediction |
| ------ | ---------- |
| 1      | 1          |
| 0      | 2          |
| …      | …          |
| 2      | 2          |

```python
column_mapping = ColumnMapping()

column_mapping.target = 'target'
column_mapping.prediction = 'prediction'
column_mapping.target_names = ['Setosa', 'Versicolour', 'Virginica']
```

If you pass the target names, they will appear on the visualizations.

You can also pass the target names as a dictionary:

```python
column_mapping.target_names = {'0':'Setosa', '1':'Versicolor', '2':'Virginica'}
```

or

```python
column_mapping.target_names = {0:'Setosa', 1:'Versicolor', 2:'Virginica'} 
```

### Option 2

Target: labels, Preds: labels.

| target        | prediction    |
| ------------- | ------------- |
| ‘Versicolour’ | ‘Versicolour’ |
| ‘Setosa’      | ‘Virginica’   |
| …             | …             |
| ‘Virginica’   | ‘Virginica’   |

```python
column_mapping = ColumnMapping()

column_mapping.target = 'target'
column_mapping.prediction = 'prediction'
```

## Multiclass probabilistic classification

Target: labels, Preds: columns named after labels.

| target      | ‘Versicolour’ | ‘Setosa’ | ‘Virginica’ |
| ----------- | ------------- | -------- | ----------- |
| ‘Setosa’    | 0.98          | 0.01     | 0.01        |
| ‘Virginica’ | 0.5           | 0.2      | 0.3         |
| …           | …             |          |             |
| ‘Virginica’ | 0.2           | 0.7      | 0.1         |

```python
column_mapping = ColumnMapping()

column_mapping.target = 'target'
column_mapping.prediction = ['Setosa', 'Versicolour', 'Virginica']

```

Naming the columns after the labels is a requirement. You cannot pass a custom list.

## Binary classification

### Option 1

Target: encoded labels, Preds: encoded labels + pos\_label + Optional\[target\_names]

| target | prediction |
| ------ | ---------- |
| 1      | 1          |
| 0      | 1          |
| …      | …          |
| 1      | 0          |

By default, Evidently expects the positive class to be labeled as ‘1’. If you have a different label, specify it explicitly.

```python
column_mapping = ColumnMapping()

column_mapping.target = 'target'
column_mapping.prediction = 'prediction'
column_mapping.target_names = ['churn', 'not_churn']
column_mapping.pos_label = 0

```

If you pass the target names, they will appear on the visualizations.

### Option 2

Target: labels, Preds: labels + pos\_label

| target       | prediction   |
| ------------ | ------------ |
| ‘churn’      | ‘churn’      |
| ‘not\_churn’ | ‘churn’      |
| …            | …            |
| ‘churn’      | ‘not\_churn’ |

Passing the name of the positive class is a requirement in this case.

```python
column_mapping = ColumnMapping()

column_mapping.target = 'target'
column_mapping.prediction = 'prediction'
column_mapping.pos_label = 'churn'

```

## Binary probabilistic classification

### Option 1

Target: labels, Preds: columns named after labels + pos\_label

| target       | ‘churn’ | ‘not\_churn’ |
| ------------ | ------- | ------------ |
| ‘churn’      | 0.9     | 0.1          |
| ‘churn’      | 0.7     | 0.3          |
| …            | …       |              |
| ‘not\_churn’ | 0.5     | 0.5          |

Passing the name of the positive class is a requirement in this case.

```python
column_mapping = ColumnMapping()

column_mapping.target = 'target'
column_mapping.prediction = ['churn', 'not_churn']
column_mapping.pos_label = 'churn'

```

### Option 2

Target: labels, Preds: a column named like one of the labels + pos\_label

| target       | ‘not\_churn’ |
| ------------ | ------------ |
| ‘churn’      | 0.5          |
| ‘not\_churn’ | 0.1          |
| …            | …            |
| ‘churn’      | 0.9          |

```python
column_mapping = ColumnMapping()

column_mapping.target = 'target'
column_mapping.prediction = 'not_churn'
column_mapping.pos_label = 'churn'

```

Both naming the column after one of the labels and passing the name of the positive class are requirements.

### Option 3

Target: encoded labels, Preds: one column with any name + pos\_label

| target | prediction |
| ------ | ---------- |
| 1      | 0.5        |
| 1      | 0.1        |
| …      | …          |
| 0      | 0.9        |

```python
column_mapping = ColumnMapping()

column_mapping.target = 'target'
column_mapping.prediction = 'prediction'
column_mapping.pos_label = 1
column_mapping.target_names = ['churn', 'not_churn']

```

If you pass the target names, they will appear on the visualizations.